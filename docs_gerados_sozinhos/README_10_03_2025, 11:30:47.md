```markdown
# Vector Database API for Semantic Search

## 1. Project Overview

This project provides a Flask API for generating text embeddings and performing semantic similarity searches. It leverages a pre-trained sentence embedding model to convert text into vector representations, which are then used for similarity comparisons. The API supports storing embeddings in both JSONL files and a PostgreSQL database with the `vector` extension, enabling efficient retrieval of semantically similar documents based on a query. This system is particularly well-suited for applications like code documentation search and retrieval.

## 2. File Structure

```
├── api_endpoint_models/
│   ├── app.py             # Flask API application defining endpoints
│   ├── db_connect.py      # Handles PostgreSQL database interactions
│   ├── model_loader.py    # Loads and runs the sentence embedding model
│   └── requirements.txt   # Python dependencies for the API
├── infra/
│   ├── .gitkeep           # Placeholder to track the directory in Git
│   └── postgresql/
│       ├── compose.yaml   # Docker Compose file for PostgreSQL setup
│       └── init/
│           └── init.sql   # SQL script to initialize the database schema
└── README.md            # Project documentation (this file)
```

**Description of Directories and Files:**

*   **`api_endpoint_models/`**: Contains all the Python code for the API application.
    *   **`app.py`**: The main Flask application file. It defines API endpoints for health checks, embedding generation, saving embeddings (to JSONL and database), and retrieval (from JSONL and database).
    *   **`db_connect.py`**:  Manages the connection to the PostgreSQL database and provides functions for inserting documents, checking for document existence, and performing similarity searches.
    *   **`model_loader.py`**:  Handles loading the pre-trained sentence embedding model from Hugging Face Transformers and provides functions for generating embeddings and calculating cosine similarity.
    *   **`requirements.txt`**: Lists the Python packages required to run the API application.
*   **`infra/`**: Contains infrastructure-related files for setting up the database.
    *   **`postgresql/`**:  Files for deploying a PostgreSQL database with vector capabilities using Docker.
        *   **`compose.yaml`**: Defines a Docker Compose service to run a PostgreSQL database with the `pgvector` extension.
        *   **`init/init.sql`**:  An SQL script executed on database initialization to create the `vector` extension, define the `documents` table schema, and create an HNSW index for efficient vector similarity search.
*   **`README.md`**: This file, providing an overview and instructions for the project.

## 3. Getting Started

Follow these steps to set up and run the project:

**Prerequisites:**

*   Docker and Docker Compose installed on your system.
*   Python 3.x installed.
*   `pip` package installer.

**Steps:**

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

2.  **Start the PostgreSQL database using Docker Compose:**
    ```bash
    cd infra/postgresql
    docker-compose up -d
    cd ../.. # Navigate back to the project root
    ```
    This command will start a PostgreSQL database instance in the background, configured with the `vector` extension and initialized with the schema defined in `infra/postgresql/init/init.sql`.

3.  **Create a Python virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate  # On Windows
    ```

4.  **Install Python dependencies:**
    ```bash
    pip install -r api_endpoint_models/requirements.txt
    ```

5.  **Run the Flask API application:**
    ```bash
    cd api_endpoint_models
    python app.py
    ```
    The API will start and be accessible at `http://localhost:5000`.

## 4. Key Features

*   **Text Embedding Generation:**  Utilizes a pre-trained multilingual sentence transformer model to generate high-quality embeddings for input text.
*   **Semantic Similarity Search:** Enables efficient semantic similarity search between query phrases and stored document embeddings using cosine distance.
*   **Database Storage with Vector Extension:** Leverages PostgreSQL with the `pgvector` extension for robust and scalable storage of vector embeddings and metadata. HNSW index is used for fast similarity queries.
*   **JSONL File Storage Option:** Provides flexibility to save and retrieve embeddings from JSONL files for simpler use cases or data export.
*   **Comprehensive API Endpoints:** Offers a range of API endpoints for:
    *   **Health Check (`/health`):** Verifies the API's availability.
    *   **Embedding Generation (`/rag`):** Generates and returns embeddings for input sentences.
    *   **Saving to JSONL (`/emb_save`):** Generates embeddings and saves them to a JSONL file along with associated data.
    *   **Retrieval from JSONL (`/retrive`):** Retrieves embeddings from a JSONL file and performs similarity search.
    *   **Saving to Database (`/to_bd`):** Generates embeddings and saves them to the PostgreSQL database, preventing duplicate entries.
    *   **Retrieval from Database (`/retrive_from_banco`):** Retrieves embeddings from the PostgreSQL database and performs similarity search.
*   **Dockerized PostgreSQL Setup:** Simplifies database deployment with a pre-configured Docker Compose setup, ensuring the necessary `vector` extension is enabled.
*   **Logging and Monitoring:** Includes logging for monitoring API activity and response times.

This API provides a solid foundation for building applications that require semantic search capabilities, particularly in domains like code documentation and knowledge retrieval.
```