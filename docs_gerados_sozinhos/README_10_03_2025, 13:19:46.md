# Vector Embedding API for Semantic Search

## 1. Project Overview

This project provides a Flask API for generating and utilizing text embeddings for semantic similarity search. It leverages a pre-trained sentence embedding model and a PostgreSQL database with the `pgvector` extension to efficiently store and retrieve document embeddings. The API is designed to facilitate tasks such as retrieving relevant code documentation based on natural language queries.

Key functionalities include:

*   Generating embeddings for text inputs.
*   Storing embeddings in JSONL files or a PostgreSQL database.
*   Performing similarity searches against stored embeddings to retrieve semantically similar documents.
*   Providing a health check endpoint for monitoring application status.

## 2. File Structure

```
.
├── api_endpoint_models/
│   ├── app.py              # Flask API application code
│   ├── db_connect.py       # Database interaction functions (PostgreSQL)
│   ├── model_loader.py     # Sentence embedding model loading and inference
│   ├── requirements.txt    # Python dependencies for the API
├── infra/
│   ├── .gitkeep            # Placeholder directory for infrastructure files
│   └── postgresql/
│       ├── compose.yaml    # Docker Compose file for PostgreSQL setup
│       └── init/
│           └── init.sql    # SQL script for database initialization
└── README.md             # Project documentation (this file)
```

**Description of Key Files:**

*   **`api_endpoint_models/app.py`**:  Contains the Flask application definition, API endpoints for embedding generation, saving, and retrieval, and request handling logic.
*   **`api_endpoint_models/db_connect.py`**:  Provides functions to connect to the PostgreSQL database and perform operations like inserting documents, checking for duplicates, and executing similarity searches.
*   **`api_endpoint_models/model_loader.py`**:  Handles loading the pre-trained sentence embedding model from Hugging Face Transformers and provides functions for generating embeddings and calculating cosine similarity.
*   **`api_endpoint_models/requirements.txt`**: Lists the Python packages required to run the API application.
*   **`infra/postgresql/compose.yaml`**: Defines a Docker Compose service to set up a PostgreSQL database instance with the `pgvector` extension enabled, suitable for vector storage and similarity search.
*   **`infra/postgresql/init/init.sql`**:  Contains SQL commands to initialize the database schema, including creating the `documents` table and setting up an HNSW index for efficient vector similarity searches.

## 3. Getting Started

To run this project, you will need Docker and Docker Compose installed. Python 3.x is required to run the API application.

**Steps:**

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd <repository_directory>
    ```

2.  **Start the PostgreSQL database using Docker Compose:**
    ```bash
    cd infra/postgresql
    docker compose up -d
    ```
    This command will start the PostgreSQL database defined in `compose.yaml` in detached mode.

3.  **Navigate back to the project root:**
    ```bash
    cd ../..
    ```

4.  **Create a Python virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate  # On Windows
    ```

5.  **Install Python dependencies:**
    ```bash
    pip install -r api_endpoint_models/requirements.txt
    ```

6.  **Run the Flask API application:**
    ```bash
    python api_endpoint_models/app.py
    ```
    The API will start and be accessible at `http://localhost:5000`.

## 4. Key Features

The API provides the following endpoints:

*   **`/health`**:
    *   Method: `GET`
    *   Description: Checks the health of the API application. Returns a success message if the application is running.

*   **`/rag`**:
    *   Method: `POST`
    *   Request Body: `{"sentences": ["sentence1", "sentence2", ...]}`
    *   Description: Generates embeddings for the input sentences and returns them as a JSON response.

*   **`/emb_save`**:
    *   Method: `POST`
    *   Request Body: `{"sentences": ["sentence1", "sentence2", ...], "function_names": ["func1", "func2", ...], "code_snippets": ["code1", "code2", ...]}`
    *   Description: Generates embeddings for the input sentences and saves them to a JSONL file along with the provided function names and code snippets.

*   **`/retrive`**:
    *   Method: `POST`
    *   Request Body: `{"query": "query phrase"}`
    *   Description: Retrieves embeddings from the JSONL file, calculates cosine similarity between the query phrase embedding and stored embeddings, and returns the top similar results.

*   **`/to_bd`**:
    *   Method: `POST`
    *   Request Body: `{"sentences": ["sentence1", "sentence2", ...], "function_names": ["func1", "func2", ...], "code_snippets": ["code1", "code2", ...]}`
    *   Description: Generates embeddings for the input sentences and saves them to the PostgreSQL database along with function names and code snippets. Prevents duplicate entries based on function names.

*   **`/retrive_from_banco`**:
    *   Method: `POST`
    *   Request Body: `{"query": "query phrase"}`
    *   Description: Retrieves embeddings from the PostgreSQL database, calculates cosine similarity between the query phrase embedding and stored embeddings, and returns the top similar results.

This API provides a robust foundation for building semantic search applications, particularly for code documentation and related use cases.